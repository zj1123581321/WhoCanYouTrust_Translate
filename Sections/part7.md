# 七 评价：你的生活能得到一个好的信用分数么

> 当反乌托邦科幻小说变成现实，你的每一个小举动都被评价，谁赢谁输?

> On 14 June 2014, the State Council of China published an ominous-sounding document called ‘Planning Outline for the Construction of a Social Credit System’.[^1] In the way of Chinese policy documents, it was a lengthy and rather dry affair but it contained a radical idea. What if there was a national trust score that rated the kind of citizen you were? 

2014年6月14日，国务院发布了《社会信用体系建设规划纲要》[^1]。从中国的政策文件来看，这是一件冗长而枯燥的事情，但它包含了一个激进的观点。如果有一个国民信用的分数来评价你是什么样的公民呢?

> Imagine a world where many of your daily activities were constantly monitored and evaluated–what you buy at the store and online, where you are at any given time, who your friends are and how you interact with them, how many hours you spend watching content or playing video games, and what bills and taxes you pay (or not). It’s not hard to picture, because most of that already happens, thanks to all those data-collecting behemoths like Google, Facebook and Instagram, or health-tracking apps such as Fitbit that can capture your moves and location at any given time. But now imagine a system where all these behaviors are rated as either positive or negative and distilled into a single number, according to rules set by the government. That would create your Citizen Score and it would tell everyone whether or not you were trustworthy. Plus, your rating would be publicly ranked against that of the entire population and used to determine your eligibility for a mortgage or a job, where your children can go to school–or even just your chances of getting a date.

想象一个世界,你的许多日常活动——你在商店和网上买的东西,在任何给定的时间你的位置,你的朋友们是谁并且你和他们怎们交流，你花多少时间看文章或玩电子游戏,和你支付账单和纳税情况(或逃税记录)。不难想象，因为这些都已经发生了，多亏了谷歌、Facebook 和 Instagram 等数据收集巨头，或者像 Fitbit 等可以随时捕捉你的行踪和位置的健康追踪应用。但是现在想象一个系统，在这个系统中，所有这些行为都被评为正面的或负面的，并根据政府设置的规则被凝练成一个数字。这样就会生成你的公民（信用）评分，它会告诉每个人你是否值得信任。此外，你的评级将与所有人的评级进行公开对比，用来决定你是否有资格申请抵押贷款或工作，你的孩子在哪里上学，~~或者只是~~你约会的机会。

> A futuristic vision of Big Brother out of control? No, it’s already getting underway in China where the government is developing a system to rate the trustworthiness of its 1.3 billion citizens. I’m sure George Orwell has rolled over in his grave a couple of times in recent years, but this idea, called the ‘Social Credit System’ (SCS), must have him doing frantic 360-degree turns in his coffin.

“老大哥”失控的未来愿景?不，这已经在中国开始施行了，政府正在开发一个系统来评估其13亿公民的可信程度。我相信近年来乔治·奥威尔(George Orwell)~~在坟墓里翻来覆去过好几次~~，但这个被称为“社会信用体系”(SCS)的概念，肯定让他在棺材里~~疯狂地做360度旋转~~。

> The Chinese government is pitching the system as a desirable way to measure and enhance ‘trust’ nationwide and to build a culture of ‘sincerity’. As the policy states, ‘It will forge a public opinion environment where keeping trust is glorious. It will strengthen sincerity in government affairs, commercial sincerity, social sincerity and the construction of judicial credibility.’[^2]

中国政府将这一制度描述为衡量和增进全国“信任”、建立“诚信”文化的理想方式。正如该政策所言，它将打造一个公众舆论环境，在这个环境中，保持信任是光荣的。加强政务诚信、商业诚信、社会诚信和司法诚信建设。

> Others aren’t so sanguine about its wider purpose. ‘It is very ambitious in both depth and scope, including scrutinizing individual behaviour and what books people are reading. It’s Amazon’s consumer tracking with an Orwellian political twist,’ is how Johan Lagerkvist, a Chinese internet specialist at the Swedish Institute of International Affairs, describes the Social Credit System (SCS).[^3] Dr Rogier Creemers, a postdoctoral scholar specializing in Chinese law and governance at the Van Vollenhoven Institute at Leiden University, who published a comprehensive translation of the plan, compared it to ‘Yelp reviews with the nanny state watching over your shoulder’.[^4]

其他人则对其更广泛的目标不那么乐观。它在深度和范围上都非常有野心，包括审查个人行为和人们正在阅读的书籍。瑞典国际事务研究所(Swedish Institute of International Affairs)中国互联网专家约翰•拉格奎斯特(Johan Lagerkvist)这样描述社会信用体系(SCS):~~它是带有一种奥威尔式的政治扭曲的亚马逊消费者追踪~~。莱顿大学范沃伦霍芬研究所(Van Vollenhoven Institute at Leiden University)专门研究中国法律和治理的博士后学者罗吉尔·克里默斯(Rogier Creemers)博士发表了该计划的完整译本

> For now, technically, participating in China’s Citizen Scores is voluntary. But by 2020 it will be mandatory. The behaviour of every single citizen and legal person in China (which includes every company or other entity) will be rated and ranked, whether they like it or not. Teachers, scientists, doctors, charity workers, government administrators, members of the judicial system and even sports figures will be under special scrutiny.[^5] ‘Big data will become the most important and most powerful driver to accelerate the modernization of governmental governance capacity,’ states the plan.[^6]

从技术上讲，目前参与中国公民评分是自愿的。但到2020年，这将是强制性的。在中国，每一个公民和法人(包括每一家公司或其他实体)的行为都会受到评级和排名，不管他们喜欢与否。教师、科学家、医生、慈善工作者、政府管理人员、司法系统成员甚至体育明星都将受到特别审查[^5]。《规划》指出，大数据将成为加快政府治理能力现代化最重要、最有力的驱动力[^6]。

> Prior to the national rollout in 2020, the government is taking a watch-and-learn approach. In this marriage between Communist oversight and capitalist can-do, the government has given a licence to eight private companies to come up with systems and algorithms for social credit scores. Predictably, data giants currently run two of the best-known projects.

在2020年全国推广之前，政府采取的是一种观察和学习的方式。在这场共产主义监督与资本主义~~“能干”(can-do)~~的联姻中，政府向 8 家私营企业发放了牌照，允许它们设计社会信用评分的系统和算法。可以预见的是，数据巨头目前运行着两个最知名的项目。

> The first is with China Rapid Finance, a partner of the social network behemoth Tencent and developer of the messaging app WeChat with more than 850 million active users. The other is run by the Ant Financial Services Group (AFSG), an affiliate company of Alibaba, and is called Sesame Credit. Ant Financial sells insurance products and provides loans to small- and medium-sized businesses. However, the real star of Ant is AliPay, its payments arm, which people use not only to buy things online but also for restaurants, taxis, school fees, cinema tickets and even to transfer money to each other.

第一个合作伙伴是社交网络巨头腾讯(Tencent)的合作伙伴、即时通讯应用微信的开发者、拥有 8.5 亿活跃用户的中国快速金融(China Rapid Finance)。另一家由阿里巴巴旗下的蚂蚁金服集团(AFSG)运营，名为芝麻信用(Sesame Credit)。蚂蚁金服销售保险产品，并向中小企业提供贷款。然而，蚂蚁金服真正的明星是其支付工具支付宝(AliPay)。人们不仅用支付宝在网上购物，还用它支付餐馆、出租车、学费、电影票，甚至是相互转账。

> Sesame Credit has also teamed up with other data-generating platforms, such as Didi Chuxing, the ride-hailing company that was Uber’s main competitor in China before it acquired the American company’s Chinese operations in 2016, and Baihe, the country’s largest online matchmaking service. It’s not hard to see how that all adds up to gargantuan amounts of ‘big data’ that Sesame Credit can tap into to assess how people behave and rate them accordingly.

芝麻信用还与其他数据生成平台展开合作，比如叫车公司滴滴出行(Didi Chuxing)和中国最大的在线婚恋服务百合网(Baihe)。2016年，滴滴出行收购了优步的中国业务，此前，滴滴出行是优步在中国的主要竞争对手。不难看出，芝麻信贷可以利用这些海量“大数据”来评估人们的行为，并据此对他们进行评级。

> So just how are people rated? Individuals on Sesame Credit are measured by a score ranging between 350 and 950 points.[^7] Alibaba does not divulge the ‘complex algorithm’ it uses to calculate the number but they do reveal the five factors taken into account. The first is credit history. For example, does the citizen pay their electricity or phone bill on time? Do they repay their credit card in full? Next is fulfilment capacity, which it defines in its guidelines as ‘a user’s ability to fulfil his or her contract obligations’. The third factor is personal characteristics, which is verifying personal information such as someone’s mobile phone number and address. But it’s the fourth category, behaviour and preferences, where it gets interesting and, some might say, more sinister.

那么人们是如何被评价的呢?芝麻信用的评分范围在 350 到 950 分之间[^7]。阿里巴巴没有透露其计算数字所用的“复杂算法”，但透露了其中考虑的五个因素。首先是信用记录。例如，市民是否按时缴纳电费或电话费?他们会全额偿还信用卡吗?其次是履约能力，它在其指导方针中将其定义为“用户履行其合同义务的能力”。第三个因素是个人特征，即验证个人信息，如某人的手机号码和地址。但这是第四个类别，行为和偏好，它很有趣，或者说，更险恶。

> Under this system, something as innocuous as a person’s shopping habits become a measure of character. Alibaba admits it judges people by the types of product they buy. ‘Someone who plays video games for ten hours a day, for example, would be considered an idle person,’ says Li Yingyun, Sesame’s technology director.[^8] ‘Someone who frequently buys diapers would be considered as probably a parent, who on balance is more likely to have a sense of responsibility.’[^9] So if a citizen is buying socially approved items, like baby supplies or work shoes, their score rises. But if they’re buying Clash of Clans, Temple Run 2 or any video game, and thus looking like a lazy person, their score takes a negative hit. (I wonder how long it will take to get to the point where the system can judge their behaviour within a game? Maybe they will get a few points for being a ‘nicer’ player by, say, helping another player’s avatar in World of Warcraft.)

在这种制度下，一些无害的东西，比如一个人的购物习惯，也会成为个人特征的衡量方法。阿里巴巴承认，它根据人们购买的产品类型来判断他们（的个人特征）。芝麻信用的技术总监李英云(音)说[^8]：“举例来说，每天打 10 个小时电子游戏的人会被认为是一个懒散的人”。“经常买尿布的人可能会被认为是父母——一般而言更有责任感。”[^9]因此，如果一个公民购买了社会认可的物品，比如婴儿用品或工作鞋，他们的分数就会上升。但如果他们购买的是《部落冲突》、《神庙逃亡2》或任何电子游戏，他们也会因此看起来像个懒散的人，他们的分数就会受到负面影响。(我想知道系统需要多长时间才能判断他们在游戏中的行为?)或许他们会因为成为一个“更好的”玩家而获得一些分数，比如帮助另一个玩家在魔兽世界中的化身。

> ![](https://ws1.sinaimg.cn/large/005JCdHFly1g0afoqhth3j30a10g0t9z.jpg)
>
> So the system not only investigates behaviour–it shapes it. It ‘nudges’ each of those closely monitored citizens away from purchases and behaviours the government does not like.

因此，这个系统不仅研究行为——它还塑造行为。它“推动”每一个受到密切监控的公民远离政府不喜欢的交易和行为。

> And it’s not just about purchases or pastimes. Friends matter, too. The fifth category is interpersonal relationships. What do their choice of online friends and their interactions say about the person being assessed? Sharing what Sesame Credit refers to as ‘positive energy’ online, nice messages about the government or how well the country’s economy is doing, will make your score go up. For anyone who’s read The Circle by Dave Eggers, or seen the film, this might sound nightmarishly familiar. ‘You and your ilk will live, willingly, joyfully, under constant surveillance, watching each other always, commenting on each other, voting and liking and disliking each other, smiling and frowning, and otherwise doing nothing much else,’[^10] writes Eggers. ‘Secrets are lies. Sharing is caring. Privacy is theft.’[^11]

不仅仅是购物或娱乐。朋友也很重要。第五类是人际关系。对于被评估的人，他们选择的线上好友和他们之间的互动说明了什么?在网上分享芝麻信用(Sesame Credit)所称的“正能量”、有关政府或中国经济状况的正面信息，会让你的分数上升。对于任何读过戴夫·埃格斯(Dave Eggers)的《圆圈》(The Circle)，或看过这部电影的人来说，这听起来可能非常熟悉。[^10]埃格斯写道:“你和你的同类将会快乐地生活在持续不断的监视之下，永远注视着对方，评论对方，投票，喜欢或不喜欢对方，微笑或皱眉，除此之外什么都不做。” “秘密是谎言。分享是关怀。隐私是盗窃。”[^11]

> Alibaba is adamant that, currently, anything negative posted on social media does not affect scores (we don’t know if this is true or not because the algorithm is secret). But you can see how this might play out when the government’s own Citizen Score system officially launches in 2020. Even though there is no suggestion yet that any of the eight private companies involved in the ongoing pilot scheme will ultimately be responsible for running the government’s own system, it’s hard to believe that the government will not want to extract the maximum possible amount of data for its SCS from the pilots–particularly Alipay’s Sesame and Tencent’s WeChat. If that happens, and continues as the new normal under the government’s own SCS, it will result in private platforms acting essentially as spy agencies for the government. They may have no choice. ‘Government and big internet companies in China can exploit “big data” together in a way that is unimaginable in the West,’ says Creemers. ‘There are ample reasons to assume that whatever data the Chinese government wants, it can get.’

阿里巴巴坚称，目前社交媒体上的任何负面消息都不会影响分数(我们不知道这是真的还是假的，因为算法是保密的)。但你可以看到，当政府自己的公民评分系统在2020年正式启动时，情况可能会如何。虽然还没有建议,任何的八个私营企业参与正在进行的试点计划最终将负责运行政府自己的系统,很难相信政府不会想提取最大可能的数据量的SCS的人员支付宝的芝麻和腾讯WeChat。如果这种情况发生，并继续作为政府自己的SCS下的新常态，它将导致私人平台基本上充当政府的间谍机构。他们可能别无选择。克里默斯说，中国政府和大型互联网公司可以一起利用“大数据”，这在西方是不可想象的。有充分的理由认为，无论中国政府想要什么数据，它都能得到。

> Posting dissenting political opinions or links mentioning Tiananmen Square has never been wise in China but now it could directly hurt a citizen’s rating. But here’s the real kicker. The system could have a Kevin Bacon-like connection built in. A person’s own score will depend on what their online friends say and do, beyond their own contact with them. If someone they are connected to online posts a negative comment on, say, the Shanghai stock market collapse (a massive embarrassment to the Chinese regime), their own score will also be dragged down. Talk about guilt by association.

在中国，张贴反对的政治观点或提及天安门广场的链接从来都不是明智的做法，但现在它可能会直接损害公民的评分。但真正的问题是，该系统可以内置类似 Kevin bacon 的连接。一个人的分数将取决于他的网上朋友说了什么，做了什么，~~而不仅仅是他们自己的联系方式~~。如果与他们有联系的人在网上发表负面评论，比如，上海股市崩盘(中国政府的一大尴尬)，他们自己的分数也会被拉低。~~通过关联谈论负罪感~~。

> So why have millions of people already signed up to what amounts to a trial run for a publicly endorsed government surveillance system?[^12] There may be darker, unstated reasons–fear of reprisals, for instance, for those who don’t put their hand up–but there’s also a lure, in the form of rewards and ‘special privileges’ for those who show themselves to be ‘trustworthy’ on Sesame Credit.

那么，为什么数以百万计的人已经签署了相当于一个公开认可的政府监控系统的试运行协议呢?[^12]可能有些更加黑暗的、没有说明的原因——害怕报复，比如，对那些不参与的人。但也有诱惑，通过奖励和“特权”的形式给予那些在芝麻信用上显示出他们是“值得信任的”人。

> If their score reaches 600, they can take out a ‘Just Spend’ loan of up to 5,000 yuan (around $1,000) to use to shop online, as long as it’s on an Alibaba site.[^13] Reach 650 points, they may rent a car without leaving a deposit.[^14] They are also entitled to faster check-in at hotels and use of the VIP check-in at Beijing Capital International Airport. Those with more than 666 points can get a cash loan of up to 50,000 yuan (more than $10,000), obviously from Ant Financial Services. Get above 700, they can apply for Singapore travel without supporting documents, such as an employee letter. And at 750, they get fast-tracked application to a coveted pan-European Schengen visa. ‘I think the best way to understand the system is as a sort of bastard love child of a loyalty scheme,’ says Rogier Creemers. ‘Like the trust systems on eBay put together with an air-miles-type rewards programme.’[^15]

如果他们的评分达到 600 分,只要是在阿里巴巴网站上，他们可以使用“花呗”的额度高达 5000 元(约1000美元)用于网上购物。[^13]评分达到 650 分,他们可以免押金租一辆车。[^14]他们也有权快速入住酒店和在北京首都国际机场使用 VIP 通道。超过 666 分的学生可以从蚂蚁金服获得最高 5 万元( 1 万美元以上)的现金贷款。如果超过 700 分，他们可以申请去新加坡旅游，不需要任何证明文件，比如员工信。750岁的他们能快速申请到梦寐以求的泛欧申根签证。“我认为，理解这个体系的最佳方式是把它当成忠诚计划的私生子，”罗吉尔•克里默斯(Rogier Creemers)说。“就像信任系统在eBay上加上一个air-miles-type奖励计划”。[^ 15]

> Higher scores have already become a status symbol, with almost 100,000 people bragging about their scores on Weibo (the Chinese equivalent of Twitter) within months of launch.[^16] A citizen’s score can even increase or decrease their odds of getting a date or a marriage partner, because the higher their Sesame rating, the more prominent their dating profile is on Baihe. ‘A person’s appearance is very important… but it’s more important to be able to make a living,’ says Zhuan Yirong, vice president of Baihe. ‘Your partner’s fortune guarantees a comfortable life.’[^17] More than 15 per cent of Baihe users are currently choosing to display prominently their Sesame scores on their profiles. It shows how readily many people will buy into a system like this, apparently blind to all its other implications.

更高的分数已经成为一种身份象征，(芝麻信用）在微博(相当于中国的Twitter)上线后的几个月内，就有近 10 万人在微博上炫耀自己的分数。[^ 16]公民的得分甚至可以增加或减少获得约会或结婚对象的可能性，因为他们的芝麻信用评级越高,他们的交友资料在百合网位置更能优先显示。百合网副总裁庄一荣说，一个人的外表很重要，但更重要的是能够生存。你伴侣的财富保证了他/她过上舒适的生活。[^ 17]超过 15% 的百合用户目前选择突出显示芝麻成绩档案。它显示出许多人是多么容易接受这样一个系统，而明显对它的所有其他影响视而不见。

> Sesame Credit already offers tips to help individuals improve their ranking, including warning about the downsides of friending someone who has a low score. Undoubtedly, it won’t be long before we see the rise of score advisors, who will share tips on how to gain points, or reputation consultants willing to offer expert advice on how strategically to improve a ranking or get off the trust-breaking blacklist. I wonder if people will hire reputation auditors to look into the assessments made about them. It could be a lucrative new venture for accounting outfits like PricewaterhouseCoopers (PwC).

> We’re also bound to see the birth of reputation black markets selling under-the-counter ways to boost trustworthiness. In the same way that Facebook ‘likes’ and Twitter followers can be paid for, and positive reviews on the darknet can be bought, individuals will pay to manipulate their score. But what happens to the poor and less educated people who can’t afford or don’t know how to enhance their score? Those who can’t game or manipulate the system will be at a disadvantage.[18](#18__Cathy_O_Neil_covers_this_poi) And what about keeping the system secure? Cyber hackers (some even state-backed) could go in and change or steal the digitally stored information. How much will a spouse or a future employee pay to purchase data on everything from the comments made in chatrooms to a history of every hotel room someone has checked into? It will give a whole new meaning to a ‘background check’.

> There’s a compelling psychological reason people are willing to sign up to systems like this. Sesame Credit has tapped into a fundamental aspect of what makes us human: the desire to push ourselves to be better. We have been ranked and put on a curve since we were in primary school; most of us are wired to want continually to level up, to score higher than others. We’re caught on the ‘hedonic treadmill’, the term psychologists give to the desire to keep improving our current situation. We stay on it because satisfaction and happiness seem forever just out of reach. For instance, when we finally reach a longed-for salary level, we’ll experience a temporary high but before long we are hankering after more money. Or we post something on Facebook and it gets 121 ‘likes’; the pleasure soon gives way to a desire to post something that gets 125 or more ‘likes’. In the world of Citizen Scores, this means as soon as we reach one level, we not only will need but will want to ramp upwards. The desired social rung will always remain tantalizingly out of our grasp, making it almost impossible to be content with who and where we are.

> Sesame Credit plays on this in several ways. For example, it encourages users to guess whether they have a higher or lower score than their friends. When they check their own score, it also displays all their friends’ scores. But it’s not simply about competitiveness. It also means they can see who might be dragging them down. Conversely, people will be tempted to cultivate friends with good reputations for their own advantage. Want a loan to start a business? Better start being extra nice to influential people with high trust ratings and drop the losers.

> It will create some bizarre family dinner conversations. ‘Honey, I noticed your score dropped by thirty-eight points today,’ says a wife to her husband. ‘You know we need to maintain a high score to get that home improvement loan. And have you forgotten that our family score goes on our son’s college application next month? So what exactly did you do today, points-wise?’

> As I learned more and more about China’s Citizen Scores, I kept thinking about the bestselling novel Super Sad True Love Story, which came out in 2010. It is set in a dystopian New York City in the not-too-distant future and author Gary Shteyngart imagines credit poles lining the streets that publicly announce your credit rating as you pass by. Lenny Abramov, a Russian Jew and the main American character, is something of a throwback because he still believes in the unquantifiable qualities of individuals. His boss and everyone else tell him that that kind of touchy-feely stuff doesn’t matter and that he needs to get his rating up.[19](#19__Super_Sad_True_Love_Story__G)

> Super Sad features a number of gadgets, and one that Lenny wears is an ‘Äppäräti’, a neck pendant with ‘RateMe Plus’ technology. It broadcasts personal data such as life expectancy, current cholesterol levels and even the wearer’s sexual history. ‘Let’s say you walk into a bar, it says, “OK, you’re the third-ugliest man in here, but you have the fifth-best credit rating,”’ explained Gary Shteyngart in an interview with The Atlantic.[20](#20___Will_Social_Media_Make_Us_A) Forget ‘beer goggles’, even Google Glass–Äppäräti allows the wearer to check other people’s ratings in real time to ensure they are not hooking up with someone dishonest, or at least rated as dishonest. It’s not a very happy or trusting world. It’s narcissistic, ruthless and exhibitionist. And it might not be far off.

> Shteyngart’s haunting satire is a commentary on society’s obsession with needing to know where everyone else stands. It illustrates the perils of oversharing information with strangers and how everything from credit scores to health records could come to define us publicly, and with grave consequences, despite the whole business being made to look like an enticing game.

> Indeed, Sesame Credit is basically a ‘big data’ gamified version of the Communist Party’s surveillance methods; the disquieting dang’an. The regime kept a dossier on every individual that tracked political and personal transgressions. A citizen’s dang’an followed them for life, from schools to jobs. People started reporting on friends and even family members, raising suspicion and lowering social trust in China. The same thing will happen with digital dossiers. People will have an incentive to say to their friends, spouses, family and colleagues, ‘Don’t post that. I don’t want you to hurt your score but I also don’t want you to hurt mine.’

> The social pressure to conform to the party line and avoid any form of dissent will be immense. Negative or even contrary opinions will have no place. It’s mind-blowing to imagine the sameness this system encourages, how it will stamp out individualism. Who will dare to speak out? Maya Wang, a spokesperson for Human Rights Watch China, based in Hong Kong, sees ‘a scary vision of the future’ in the system: currently there is intensive surveillance of ‘sensitive groups, such as dissidents, but the Social Credit System goes to another level. This is an effort of surveillance of all people,’ she says.

> Rogier Creemers wholeheartedly agrees with Wang. ‘The aim [in East Germany] was limited to avoiding a revolt against the regime. The Chinese aim is far more ambitious: it is clearly an attempt to create a new citizen.’[21](#21__See__China_rates_its_own_cit)

> The new system reflects a cunning paradigm shift. As we’ve noted, instead of trying to enforce stability or conformity with a big stick and a good dose of top-down fear, the government is attempting to make obedience feel like gaming. It is a method of social control dressed up in some points-reward system. It’s gamified obedience.

> In a trendy neighbourhood in downtown Beijing, the BBC news services hit the streets in October 2015 to ask people about their Sesame Credit ratings. Most of the residents spoke about the upsides. But then, who would publicly criticize the system? Ding, your score might go down. ‘It is very convenient,’ one young woman said, smiling at the camera and proudly showing the journalist the score on her phone. ‘We booked a hotel last night using Sesame Credit and we didn’t need to leave a cash deposit.’[22](#22__See__China_s__social_credit) Alarmingly, few people seemed to understand that a bad score could hurt them in the future, preventing them from, say, signing a lease. Even more concerning was how many people, despite signing up for Sesame Credit, had no idea that they were being constantly rated.

> That kind of trusting ignorance is familiar, even if, in this case, it’s taking place in a far more advanced form of dystopia. Think of all those Facebook users who were surprised to find out they were being used as data lab rats. We sign up to all kinds of services without really knowing what we’re agreeing to and what is in our control to reject, if we choose to do so.

> Currently, Sesame Credit does not directly penalize people for being ‘untrustworthy’–it’s far more effective to lock people in with treats for good behaviour. But Hu Tao, Sesame Credit’s chief manager, warns people that the system is designed so that ‘untrustworthy people can’t rent a car, can’t borrow money or even can’t find a job’.[23](#23__See__Orwellian_Dystopia_or_T) She has even disclosed that Sesame Credit has approached China’s Education Bureau about sharing the list of its students who cheated in national examinations, in order to make them pay in the future for their dishonesty.[24](#24__See__From_the_end_of_sesame)

> Penalties are set to change dramatically when the government system becomes mandatory in 2020. Indeed, on 25 September 2016, the State Council General Office updated its policy entitled ‘Warning and Punishment Mechanisms for Persons Subject to Enforcement for Trust-Breaking’.[25](#25___State_Council_Guiding_Opini) The overriding principle is simple: ‘If trust is broken in one place, restrictions are imposed everywhere,’ the policy document states. The punishments will seriously affect the social mobility of any transgressors.

> For instance, people with low ratings will have slower internet connectivity; restricted access to more desirable restaurants, nightclubs or golf courses; and the removal of the right to travel freely abroad with, I quote, ‘restrictive control on consumption within holiday areas or travel businesses’. Scores will influence a person’s rental application, their ability to get insurance, eligibility for a loan and even social security benefits. Chinese citizens with low scores will not be hired by certain employers and will be forbidden altogether from obtaining some jobs, including in the civil service, journalism and legal fields, where of course you must be deemed trustworthy. People who do not rate well will also be restricted when it comes to enrolling themselves or enrolling their children in high-paying private schools. I am not fabricating this list of punishments. It’s the reality Chinese citizens will face. As the government document repeatedly states, the Social Credit System will ‘allow the trustworthy to roam everywhere under heaven while making it hard for the discredited to take a single step’.[26](#26__Ibid__See_also__China_s_New)

> Once again, life mirrors art. The system is strikingly similar to an episode of Black Mirror, the critically acclaimed dystopian sci-fi television series. Each episode has a different cast, a different setting, even a different reality, notes Charlie Brooker, the creator of this darkly witty series. ‘But they’re all about the way we live now–and the way we might be living in ten minutes’ time if we’re clumsy.’[27](#27__See__Charlie_Brooker__the_da) Meaning if we do not carefully handle new technologies, they will pull us into a strange future much sooner than we expect. Indeed, many of the imagined scenarios have since become reality, including a chatbot that mimics deceased relatives (yes, this now exists–it is called Replika) and an obnoxious TV character who runs for political office to shake up a corrupt system. Not to mention a British PM who is forced to perform an insalubrious act with a pig on national television.

> ‘Nosedive’, the first episode of the third season, envisions a world in which each of us continually chases after a desirable rating that sums up how people feel about us in real time. Your score, out of five stars, is affected by everyone–family members, friends, co-workers and anonymous passers-by–and is used for everything, no matter how trivial. Did the barista pour a nice swirl of milk on your coffee? You can reward him for that. Did a woman look you up and down the wrong way in your thirty-second elevator ride? You can make her pay for that. Be warned, though, your own rating might fall if she returns fire and rates you negatively.

> The main character, Lacie Pound, lives her life constantly trying to please everyone in exchange for a few precious points. She has to work hard to maintain her solid but not outstanding 4.2 rating. She even practises her fake smile in the bathroom mirror every morning. Her value in this world is equivalent to her points, which she checks obsessively after every tiny interaction.

> What does Lacie’s life tell us about the way the world is moving? Luciano Floridi, professor of philosophy and ethics of information at the University of Oxford, and the director of research at the Oxford Internet Institute, has an interesting way of framing it. Many make the claim to be an expert on ‘digital disruption’, but Floridi is the real deal. He is currently serving as the only ethicist on Google’s advisory committee on the European Union’s ‘right to be forgotten’ ruling. It’s a role that has seen him crowned ‘Google’s Philosopher’.

> According to Floridi, there have been three critical ‘de-centring shifts’ that have altered our view in self-understanding: Copernicus’s model of the earth orbiting the sun; Darwin’s theory of natural selection; and Freud’s claim that our daily actions are controlled by the unconscious mind.[28](#28__See__Lessons_from_Luciano_Fl)

> Floridi believes we are now entering the fourth shift in our world, as what we do online and offline merge into an onlife. He asserts that as our world increasingly becomes an infosphere, a mixture of physical and virtual experiences, we are acquiring onlife personality–different from who we innately are in the ‘real world’ alone.[29](#29__See_The_Fourth_Revolution__L) We see this writ large on Facebook, where people present a carefully edited or idealized portrait of their lives.[30](#30__Bret_Easton_Ellis_s_article) When I look at some of my friends’ streams–beautiful pictures of holidays and their kids angelically dressed up in costumes–I wonder, is this the same friend complaining about her husband and bratty five-year-old? I do the same. I edit the flaws and inconsistencies in my life, disguising my true messy self.

> In Black Mirror, Lacie’s onlife personality is the extreme version of the future Floridi is talking about. Her life has become an exhausting, dramatic public performance. She has discovered that the only way she can afford her dream apartment is by raising her rating. So she visits a score counsellor for advice. Then, out of the blue, Naomi, an old school friend and social media star with a higher rating, asks Lacie to be maid of honour at her wedding. With many prime influencers (high-ranking wedding guests) attending, Lacie is convinced a tear-jerking bridesmaid’s speech will get her the upvotes she needs. The speech, of course, turns into a disaster but that’s not the point here. Or maybe it is.

> The rating system in Black Mirror is based on social approval, on likes and stars; as we see with Lacie, it encourages people to base relationships on personal gain and to fake behaviour. Disturbingly, that episode is not so very far from the ‘onlife’ we are living right now.

> Think about your Uber experiences. Are you just a little bit nicer and friendlier to the driver because you know you will also be rated? Indeed, judgement and scores are a two-way street. Some days, I like my conversations with drivers. I appreciate the serendipitous connections that sometimes emerge because I sit in the front and we talk. However, there are times I wish my Uber ride could be a simple transaction: where the driver does not know my name or have a picture of me; where I feel no pressure to be nice; where I am not asked what I do or how many kids I have.

> I once berated my husband down the phone during a trip because he told me he was running late, again. I was tired. It hadn’t been a particularly good day. The driver said to me, ‘If I were your husband and you shouted like that, I would be late.’ It’s rude that I shouted in his car but, frankly, it’s none of his business.

> The pressure to be rated means I am tempted to be falsely polite and not authentic. Yet it’s not as if I am unused to being rated and reviewed. After a speech, I can see exactly how many people thought it was ‘fantastic’ or ‘a waste of time’. People ‘like’ or ‘dislike’ my talks on TED, my slides on Slideshare and my posts on Medium. My students at Oxford break my teaching ability down into a detailed survey. People send me not just complimentary remarks but also scathing comments about my ideas and articles. I have learned to be comfortable having all my imperfections pointed out and even so I still worry about how I measure up on an Uber ride. I am human; I need to be liked and–more to the point–I want drivers to continue to pick me up.

> Yet I don’t want to worry ceaselessly about how I am being rated, whether I am late or punctual, rude or a darling, dirty or clean. I am frightened of ending up like Lacie. I am frightened my children will live in a society where scores become the ultimate truth of who they are. A paranoid world where they are under never-ending pressure to present an idealized portrait of their lives, not just for ‘likes’ but because of fear of how they’re measuring up against others, minute by minute, year by year, and how it will affect their future prospects. How will I teach them what it means to be your authentic self?

> The information we liberally post about ourselves today might end up being rated in some way down the track–but that doesn’t stop us. We have become hooked, literally, on displaying our lives and doings. A few years ago, Diana Tamir, an associate professor of psychology at Princeton University, and Jason Mitchell of Harvard’s Neuroscience Lab, published a paper titled ‘Disclosing information about the self is intrinsically rewarding’. Surveys of internet use show that more than 80 per cent of posts to social media sites consist simply of announcements about a user’s immediate experience, such as what they are about to eat for dinner.[31](#31__For_the_proceedings_of_the_2) The researchers asked participants to undergo functional magnetic resonance imaging (fMRI) scans while making these kinds of posts, to see what happens to their brains. And what happens is that our reward centres light up, just as they do with primary rewards such as food and sex.[32](#32___Disclosing_information_abou) That is why we strive to post more. As Dave Eggers brilliantly puts it, it’s the addictive digital-social equivalent of snack food, ‘endless empty calories’. And it’s far from nourishing.

> Uber ratings are nothing compared to Peeple, an app launched in March 2016, which is like a Yelp for humans.[33](#33__Peeple__a_people_rating_app) It allows you to assign ratings and reviews to everyone you know–your neighbour, your boss, your teacher, your spouse and even your ex. A profile displays a ‘Peeple Number’, a score based on all the feedback and recommendations you receive. Worryingly, once someone puts your name in the Peeple system, it’s there and there’s nothing you can do about it. You can’t opt out. You must use your real name to leave a review, be over twenty-one and of course have a Facebook account. You must also affirm that you know the person you are rating based on one of three categories: professional, personal or dating (that is, how good they are at dating). The app is basically allowing you to judge and publicly reduce people to a grade without consent. Sound familiar?

> Peeple has forbidden certain bad behaviours including mentioning private health conditions, expressing profanities or being sexist (however you objectively assess that). There are, however, very few rules on how people are graded or standards about transparency. The app does include a feature called a ‘Truth License’. According to the company’s press release, ‘The Peeple Truth License shows you everything that has been written about a person, whether it was published live on their profile or not. This allows you to make better decisions about the people around you.’ One of the key reasons why Nicole McCullough, Peeple co-founder and a mother of two, developed the app was that, in a world where people don’t know their neighbours, she wanted help to decide whom to trust with her kids.[34](#34___Everyone_you_know_will_be_a)

> Fittingly, the founders have been publishing a reality documentary on YouTube about every step involved in building Peeple. ‘It doesn’t matter how far apart we are in likes or dislikes,’ co-founder Julia Cordray tells a total stranger in a bar in episode ten of the YouTube documentary. ‘All that matters is what people say about us.’[35](#35__See__Peeple_Watching_Webisod)

> What are the consequences of boxing people into a number and a value?

> This question comes to life in a particularly memorable scene in Black Mirror. Lacie is at the airport on her way to Naomi’s wedding. Dressed like a pink pastel daydream, she approaches the check-in counter, all smiles. When she places her phone on the scanner her details, including her rating and PMA (positive mental attitude), flash on the check-in agent’s screen. Unfortunately, her flight is cancelled and the airline representative can’t book her on to another standby flight because Lacie’s social credit score has dropped. On the way to the airport, her score dipped to a 4.183 after she got into a squabble with a woman while getting into her taxi. Her explanation doesn’t matter; the system automatically blocks the agent from booking her on to the flight without the correct 4.2 rating. She ends up hitching a ride with a female truck driver who has a dismal 1.4 rating. The trucker shares the moving story of how she, too, was obsessed with her rating, until her husband got terminal cancer. He was denied treatment he badly needed; it was given to another patient with a higher score. ‘So I figure,’ the trucker tells Lacie with a smile, ‘fuck it.’ It makes me wonder, will we see similar movements of anti-rating people happy to be poorly ranked?

> Black Mirror has become somewhat of a Magic 8 Ball, predicting the future. China’s trust system might be voluntary as yet, but it’s already having Lacie-like consequences. In February 2017, China’s Supreme People’s Court announced that 6.15 million people in the country had been banned from taking flights over the past four years for social misdeeds. The travel ban is being pointed to as the first indication of how people blacklisted in the Social Credit System, so called ‘trust-breakers’, will be punished. ‘We have signed a memorandum… [with over] 44 government departments in order to limit “discredited” people on multiple levels,’ says Meng Xiang, head of the executive department of the Supreme Court.[36](#36___China_penalizes_6_7m_debtor) Another 1.65 million people cannot take trains, because they are on the social credit blacklist for misdemeanours.[37](#37__See__4_9_mln_people_with_poo) They have been downgraded and branded as second-class citizens. This isn’t TV. It isn’t marketing. It’s reality.

> Where these systems really descend into nightmarish territory is that the trust algorithms used are unfairly reductive. They don’t tell the whole story. They don’t take into account context and valid reasons for a bad day. For instance, one person might miss paying a bill or a fine because they were in hospital; another may simply be a freeloader. But there is no one sitting and analysing every Citizen Score assessment, going, ‘Oh, okay, she was having an operation and that explains why she didn’t pay her credit card.’ And therein lies the urgent challenge facing all of us in the digital world, and not just the Chinese. If life-determining algorithms are here to stay, and it certainly looks that way, we need to figure out how they can embrace the nuances, inconsistencies and contradictions inherent in human beings. We need to work out how they can reflect real life.

> You could see China’s so-called ‘trust plan’ as Orwell’s Nineteen Eighty-Four meets Pavlov’s dogs. Act like a good citizen, be rewarded and be made to think you’re having fun. It’s worth remembering, however, that personal scoring systems have been present in the West for decades.

> More than seventy years ago, two men called Bill Fair and Earl Isaac invented credit scores. They met at Stanford University in San Jose, California, where Fair was studying engineering and Isaac mathematics. They started their own company with just $400 apiece.[38](#38__See__Around_the_House__50_ye) The goal was to use predictive analytics, and the new-fangled capabilities of computers, to give lenders a unified view of a person’s credit risk. Specifically, the duo wanted to use algorithms to study customers’ past behaviour, predict future behaviour and come up with a credit score. At the time, it was regarded as a radical concept.

> Initially, the idea of credit scores didn’t take off. Fair and Isaac sent a letter to fifty of the largest lenders in the United States offering them the new technology. Only one responded. But in 1958, the first credit score, known today as FICO (short for the Fair Isaac Corporation), was created. Over the years, it has positively challenged many lenders’ practices and prejudices. ‘Good credit does not wear a coat and tie’ was the headline on one advertisement. FICO proved time and time again that race, for example, was not a predictor of good credit risk and refused to put it in their scoring system.

> Today, companies use FICO scores to determine many financial decisions, including the interest rate on our mortgage or whether we should be given a loan. The score range is 300 to 850, with the high number representing less risk to the lender or insurer. Remarkably, it wasn’t until 2003 that we could find out our actual score.[39](#39__Refer_to__Fair_and_Accurate) Before then, they had been kept a secret. And despite the significance of credit scores to our lives, repeated studies show that more than 60 per cent of Americans still do not know their score or simply have not bothered to find out.[40](#40__See__Credit_score_statistics)

> For the majority of Chinese people, it is not a case of knowing or not. In a catch-22, they have never had credit scores and so they can’t get credit. ‘Many people don’t own houses, cars or credit cards in China, so that kind of information isn’t available to measure,’ explains Wen Quan, an influential blogger who writes about technology and finance. ‘The central bank has the financial data from 800 million people, but only 320 million have a traditional credit history.’[41](#41__See__China_s__social_credit) According to the Chinese Ministry of Commerce, the annual economic loss caused by lack of credit information is more than 600 billion yuan, approximately $97 billion.[42](#42__For_annual_economic_loss_cau)

> China’s lack of a national credit system is why the government is adamant that Citizen Scores are long overdue and badly needed to fix what they refer to as a trust deficit. In a poorly regulated market, the sale of counterfeit and substandard products is a massive problem. According to the Organisation for Economic Co-operation and Development (OECD), 63 per cent of all fake goods, from watches to handbags to baby food, originate from China.[43](#43___Global_trade_in_fake_goods) In late 2008, the Chinese Ministry of Health revealed six babies had died and almost 30o,000 had fallen ill after drinking baby formula deliberately laced with melamine, a toxic chemical used in plastics and fertilizer. Turns out, a local manufacturer had intentionally added the industrial chemical to mask low protein levels in watered-down formula. Since this massive breach of trust, Chinese customers have bought baby formula milk, loads of it, from overseas. So much so that some big British retailers such as Boots and Sainsbury’s decided to set a two-can limit to prevent bulk buying to feed the Chinese market leaving a shortage of tins on the shelves.

> In January 2017, Chinese authorities discovered a ‘production hub’ of around fifty factories that were generating counterfeit products designed to look exactly like well-known brands. Jack Ma has called fake goods ‘cancer’ to Alibaba but crackdown efforts to weed out fakes have had an uphill battle. ‘Food security, counterfeiting and a lack of regulatory compliance are real issues for Chinese citizens. The level of micro corruption is enormous,’ says Rogier Creemers. ‘Up and down the ladder, trust is a huge problem in China. So if this particular scheme results in more effective oversight and accountability, it will likely be warmly welcomed.’

> The government also argues that the system is a way to bring in those people left out of traditional credit systems, such as students, low-income households and those who have never borrowed money. Professor Wang Shuqin from the Office of Philosophy and Social Science at Capital Normal University in China recently won the bid to help the government develop the system that she refers to as ‘China’s Social Faithful System’. Without such a mechanism, doing business in China is risky, she stresses, as about half of the signed contracts are not kept. ‘Especially given the speed of the digital economy, it is crucial that people can quickly verify each other’s creditworthiness,’ she says. ‘The behaviour of the majority is determined by their world of thoughts. A person who believes in socialist core values is behaving more decently.’[44](#44__For_interview_with_Professor) In other words, she regards the ‘moral standards’ the system assesses, as well as financial data, as a ‘bonus’.

> Indeed, the State Council’s primary objective is to raise the ‘honest mentality and credit levels of the entire society’ in order to improve ‘the over-all competitiveness of the country’.[45](#45___Planning_Outline_for_the_Co) In other words, the government is selling Citizen Scores as a tool to evaluate people more fairly and improve economic vitality.

> Is it remotely possible that the Social Credit System in China is in fact a more desirably transparent approach to surveillance in a country that has a long history of watching its citizens? ‘As a Chinese person, knowing that everything I do online is being tracked, would I rather be aware of the details of what is being monitored and use this information to teach myself how to abide by the rules of government?’ asks Rasul Majid, a Chinese blogger based in Shanghai who writes about behavioural design and gaming psychology. ‘Or would I rather live in ignorance and hope/wish/dream that personal privacy still exists and that our ruling bodies respect us enough not to take advantage?’[46](#46___Open_Sesame_Why_a_Digital) Put simply, Majid thinks that the system gives him a tiny bit more control over his data.

> On the one hand, a social credit system will almost certainly encourage people to act more honestly and to abide by the rules. On the other, it’s a deeply disturbing version of reputation economics that will give governments unprecedented control over what they consider good and bad ways to behave.

> When I tell people living in the Western world about the Social Credit System in China, their responses are fervent, visceral. After a speech I gave at a financial conference, a female banker remarked, ‘We routinely do things that just five years ago would have made no sense to us, but that idea is bat-shit crazy.’ Her sense of alarm was typical. Many people have asked if it is really true, if it is really happening in China. Surprisingly, very few people ask the more pertinent question, ‘Could this happen in the Western world?’ Or rather, when can we expect it?

> We already rate restaurants, movies, books and even doctors. We’ve seen how Peeple rates people. You can even rate your bowel movements online (check out ratemypoo.com if you don’t believe me). ‘Yelpers’, customers who regularly leave reviews on Yelp, will threaten hotels and restaurants with poor reviews if they don’t please them by giving them, say, complimentary drinks. Authors have Amazon scores. Airbnb hosts and guests have cleanliness scores. Teachers have RateMyProfessors.com scores. Errand runners on Taskrabbit, Deliveroo drivers and a whole plethora of other ‘gig workers’ are rated (and they rate customers back). ‘Klout scores’, that claim to identify the most influential social media users, are even appearing on some people’s résumés as proof of their stellar reputation. Fitbit captures how much you move (or don’t) and gives you a fitness score that it shares with multiple companies. On an app called DateCheck, you can even do an instant background check on someone you’ve just met in a bar. Its tagline is, fittingly, ‘Look up before you hook up’. Facebook is now capable of identifying you in pictures without seeing your face; it only needs your clothes, hair and body type to tag you in an image with 83 per cent accuracy.[47](#47__See__Facebook_can_recognise) It’s kind of like how I can recognize my husband from a hundred metres away by his gait.

> In 2015, the OECD published a study revealing that in the United States there are at least 24.9 connected devices per every one hundred inhabitants.[48](#48__See__OECD_Digital_Economy_Ou) All kinds of companies scrutinize the ‘big data’ emitted from these devices to understand our lives, desires and psyches, and to predict our future actions, in ways that we couldn’t even predict for ourselves.

> When I get on the bus on my way to work, I put on my headphones. It’s a morning ritual that gives me some sense of personal privacy in a crowded public space. My listening habits, especially the podcasts, audio books and news programmes I download, would provide a clear window into my political preferences, life stresses, religious views and various other interests. So what would happen if someone knew what I was listening to?

> On 18 April 2017, a class-action lawsuit filed in a federal court in Chicago accused a high-end audio-equipment maker of spying on its customers’ listening habits.[49](#49__See__Zak_v_Bose_Corp__U_S__D) After paying $350 for his QuietComfort 35 headphones, Kyle Zak, the lead plaintiff in the case, followed Bose’s suggestion to ‘get the most out of your headphones’ by downloading its Connect app to his smartphone. He provided his name, email address and headphone serial number as part of the sign-up process. And like most of us, he handed over his information without much thought. The app adds functions such as the ability to customize the level of noise cancellation in the headphones. But the app also tracks the music, podcasts and other audio Bose customers listen to, and violates privacy rights by selling the information to various third parties, including a data-mining company called Segment.io. Shortly after the lawsuit was filed, Bose responded with a company statement: ‘We’ll fight the inflammatory, misleading allegations made against us through the legal system. Nothing is more important to us than your trust. We work tirelessly to earn and keep it, and have for over fifty years. That’s never changed, and never will.’[50](#50___A_message_to_our_Bose_Conne)

> Regardless of the final legal outcome, the Bose case sparked further questions about the ethics of data collection. The fact is, many companies are not transparent about the data they take and what they are doing with it, or clear about how they monetize our personal information. And this applies to everything from coffee machines to headphones, running shoes to even sex toys. In 2017, We-Vibe paid more than $3.75 million to resolve privacy claims regarding vibrators remotely controlled with a ‘connect lover’ smartphone app.[51](#51__See__We_Vibes_Motion_For_App) The sex toys were secretly collecting customer data, including highly intimate details such as the date and time of each use, temperature settings and what vibration intensity and mode users selected–all of which were linked to owners’ personal email addresses. What if the data was hacked? Do we want companies (or even governments) to know how we spend our most personal time and the details of our orgasms? In April 2017, another smart sex toy faced a massive security glitch over intimate surveillance. Svakom Siime Eye, a $249 app-enabled vibrator, has a tiny built-in camera designed for either private live-streaming or to ‘know the subtle changes inside of your private areas’. The default password on the device is 88888888. If it is not reset, the device can be easily hacked. What’s more, the manufacturer, Standard Innovations, can geolocate whenever the vibrator is in use.[52](#52___Sex_toy_surveillance__more)

> Smart phones and computer webcams can be co-opted for commercial and nefarious purposes. Next in line as potential spies are the digital voice assistants such as Amazon’s Echo smart speaker called Alexa, now entering millions of our homes. Her tagline is, fittingly, ‘Just Ask’. The artificially intelligent assistant is happy to help with all kinds of requests such as ‘Alexa, what’s on my calendar today?’ or ‘Alexa, play the Coldplay song I like.’ And, of course, she is especially handy in buying things–from Amazon, that is. But what if she was asked to assist with, say, a murder trial?

> In November 2015, Victor Collins, a police officer from Arkansas, was found floating dead in the hot tub of his friend James Andrew Bates, who became a suspect. Two years later, attorney Nathan Smith, the lead prosecutor in the first-degree murder trial, ordered Amazon to hand over the audio recordings from Bates’s digital assistant, used in the Echo speakers in his home. While it’s unlikely any alleged murderer would have asked, ‘Alexa, how do I strangle someone and hide a body?’ the prosecution felt the recording might provide valuable clues as to what happened at Bates’s house the night Collins was found dead.

> Amazon’s attorneys contended the digital assistant has First Amendment rights protecting information gathered and sent by the device. Bates, however, told Amazon it could hand over the information. Maybe he believed it would prove his innocence, although it’s also possible Bates thought the Echo device was only recording snippets of audio during the few seconds during and after ‘hearing’ a command. Aside from the other issues, the case raises a key question: how can you know when your always-connected digital assistant is recording what you say?

> And it is not just tech companies that are in on this. Governments around the world are already engaged in the business of monitoring, rating and labelling their own citizens. The National Security Agency (NSA) is not the only government digital eye in the US following the movements of citizens’ lives. In 2015, the US Transportation Security Administration (TSA) quietly proposed the idea of expanding the PreCheck background checks (the ones that give you faster transport through security) to include social media records, location data and purchase history.[53](#53__See__Agreement_Between_TSA_a) The idea was scrapped after heavy criticism but that doesn’t mean it’s dead. Indeed, in February 2017, President Trump put forward a proposal to force some people entering the country to hand over their social media passwords for Facebook, Twitter, Google+, Instagram, YouTube, LinkedIn and others, so authorities could view their internet activity. The US government has said the ‘extreme vetting’ rule will apply predominantly to travellers from the seven Muslim countries–Iraq, Iran, Syria, Yemen, Somalia, Sudan and Libya–named in the controversial travel ban. ‘We want to get on their social media, with passwords: what do you do, what do you say?’ Homeland Security Secretary John Kelly told the Homeland Security Committee. ‘If they don’t want to cooperate, then you don’t come in.’[54](#54___Password_for_social_media_a)

> If you are still unconvinced that privacy is not merely in peril but already extinct, consider this: Uber has a tool it rather ominously calls ‘God View’. Until recently, it allowed all employees to access and track where and when any Uber rider travels to or from, in real time and without obtaining any kind of permission.[55](#55___A_G__Schneiderman_Announces) Running late to a meeting? Uber could know why. Shockingly, the company could analyse data to predict ‘Rides of Glory’ (RoG), the term used in a blog by an Uber data scientist to describe tracking sexual rendezvous.[56](#56__See__RoG_Blog____Blog_Uber_c) Those were customers Uber called ‘RoGers’, who booked rides between 10 p.m. and 4.00 a.m. on weekend nights, and then took a second ride home a few hours later from the previous drop-off point, presumably after one-night stands.

> In 2014, Emil Michael, a senior vice president at Uber, took the company’s ‘God View’ one step further. He suggested using the tool to monitor the rider logs and location of a Pando Daily reporter called Sara Lacey, an outspoken Uber critic who had recently accused Uber of ‘sexism and misogyny’. What’s more, the executive boasted at a dinner party attended by the likes of actor Ed Norton and Arianna Huffington that the company should spend a million dollars to use location data to dig up dirt on other journalists who had been critical of Uber to silence them. His proposal was to look into ‘your personal lives, your families’, and give the media a taste of its own medicine. The Sara Lacey incident resulted in a lawsuit led by the New York Attorney General, Eric Schneiderman, that was settled in January 2016. ‘This settlement protects the personal information of Uber riders from potential abuse by company executives and staff, including the real-time locations of riders in an Uber vehicle,’ said Attorney General Schneiderman. As part of the settlement, Uber had to pay a measly $20,000 in fines and ‘God View’ can now only be used by a select number of ‘designated employees’ and only for ‘legitimate business purposes’.[57](#57__See__Uber_to_Pay__20_000_Fin) Phew, problem solved. Hardly.

> We already live in a world of predictive algorithms that determine if we are a profitable customer, a threat, a risk, a good citizen and even if we are a trustworthy person. We are getting closer to the Chinese system–the expansion of credit scoring into life scoring–even if we don’t know it is happening. Photos, books, music, films, friendships and even money have been digitized. We are now in the early stages of digitizing identity and reputation.

> So are we inexorably headed for a future where we will all be branded online and data-mined? It’s certainly trending that way. Barring some kind of mass citizens’ revolt to wrench back privacy and personal information, we are entering an age where an individual’s actions will be judged by standards they can’t control and where that judgement cannot be erased. The consequences are not only troubling; they are permanent. Forget the right to delete and the right to be forgotten. Forget being young and foolish.

> It’s why, at the very least, we urgently need to find a way to create forgiveness for moments of madness, ineptitude or cheating. Deletion should not be outlawed. Human beings, with all our imperfections, are so much more than a number.

> While it might be too late to stop this new era, we do have choices and rights we need to be exerting now. For one thing, we need to be able to rate the raters. In his book The Inevitable, Kevin Kelly describes a future where the watchers and the watched will transparently and ceaselessly track each other.[58](#58__The_Inevitable__Kevin_Kelly) ‘Our central choice now is whether this surveillance is a secret, one-way panopticon–or a mutual, transparent kind of “coveillance” that involves watching the watchers,’ he writes. ‘The first option is hell, the second redeemable.’[59](#59___Why_you_should_embrace_surv)

> Our trust should start with individuals within government (or whichever organization is controlling the system). We need trustworthy mechanisms to make sure the ratings and data are used responsibly and with our permission. To trust the system, as we have seen, we need to reduce the unknowns. That means taking steps to reduce the opacity of the scoring algorithms. The argument against mandatory disclosures is that if you know what happens under the bonnet, the system becomes more vulnerable to being rigged or hacked. But if humans are being reduced to a rating that could have a significant impact on their lives, there must be full transparency in how the scoring works.

> In China, it seems likely that certain citizens, such as government officials and business leaders, will be deemed to be above the system. What will be the public reaction when their unfavourable actions don’t seem to affect their score? We could see a Panama Papers 3.0 for reputation fraud.

> It is still too early to know how a culture of constant monitoring plus rating will turn out. What will happen when these systems, charting the social, moral and financial history of an entire population, come into full force? How much further will privacy and freedom of speech (long under siege in China) be eroded? Who will decide which way the system goes? These are questions we all need to consider, and very soon. Today China, tomorrow a place near you. The real questions about the future of trust are not technological or economic; they are ethical.

> Indeed, if we are not vigilant, distributed trust could become networked shame. And life will become one endless popularity contest, with us all feverishly vying for the highest ratings that only a few can attain.





[^1]: ‘Planning Outline for the Construction of a Social Credit System’, China Copyright and Media, translated by Rogier Creemers, https://chinacopyrightandmedia.wordpress.com/2014/06/14/planning-outline-for-the-construction-of-a-social-credit-system-2014-2020/, accessed 3 March 2017.
[^9]: 